{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"General Trainer","provenance":[{"file_id":"1uF_dQKGaynzlWEFt7TDrNydrb4xqPXBO","timestamp":1595991315510},{"file_id":"1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD","timestamp":1595884756937}],"collapsed_sections":["l7EOtpvlLeS0","XxPj_QV43qD5","4Vk2146Ogil3","7Vz2vJeCCyZR"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"R7nzK1cRf-Ua","colab_type":"text"},"source":["#Training Setup\n","Setup variables for training and authorize Google Drive\n"]},{"cell_type":"code","metadata":{"id":"4BHckYVigKLI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1596143736825,"user_tz":240,"elapsed":22908,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"d0f00a2e-3763-48c3-bfd8-749cb5c7a4b6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YUd2wtfrqedy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596143736828,"user_tz":240,"elapsed":22904,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n","test_record_fname = '/content/drive/My Drive/training_demo/annotations/test.record'\n","train_record_fname = '/content/drive/My Drive/training_demo/annotations/train.record'\n","label_map_pbtxt_fname = '/content/drive/My Drive/training_demo/annotations/label_map.pbtxt'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"0snKjP6NhDyD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596143738406,"user_tz":240,"elapsed":24471,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"9f5abcc9-261f-4ba7-e3c0-9aa2a5296997"},"source":["batch_size = 8\n","chosen_model = 'efficientdet-d0'\n","num_steps = 1 #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \n","num_eval_steps = 1 #Perform evaluation after so many steps\n","!mkdir '/content/drive/My Drive/training_demo/training'\n","model_dir = '/content/drive/My\\ Drive/training_demo/training'\n","model__dir = '/content/drive/My Drive/training_demo/training'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/My Drive/training_demo/training’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kcR4PWC3KBau","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596143746546,"user_tz":240,"elapsed":32600,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"6c18b391-513b-4aec-e478-93052fafda07"},"source":[" \n","%mkdir /content/test/\n","\n","!cp -a '/content/drive/My Drive/training_demo/images/test/.' \"/content/test/\"\n","!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["drive  sample_data  test\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EEVh6sfHsPtc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596143746547,"user_tz":240,"elapsed":32597,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["#Save Pipeline config \n","#"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l7EOtpvlLeS0","colab_type":"text"},"source":["# Install TensorFlow2 Object Detection Dependencies"]},{"cell_type":"code","metadata":{"id":"FNNfNcSELAkU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":765},"executionInfo":{"status":"ok","timestamp":1596143844075,"user_tz":240,"elapsed":130114,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"fc046932-dd63-49ca-b650-214fa66b9b95"},"source":["#we will utilize the GPU in this tutorial. \n","#TPU configuration is recommended for faster training on larger datsets\n","!pip install -U --pre tensorflow_gpu==\"2.2.0\""],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting tensorflow_gpu==2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/bf/c28971266ca854a64f4b26f07c4112ddd61f30b4d1f18108b954a746f8ea/tensorflow_gpu-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |████████████████████████████████| 516.2MB 31kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (2.10.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (3.12.2)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (1.12.1)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (3.3.0)\n","Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (2.2.2)\n","Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (2.2.0)\n","Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (1.6.3)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (0.2.0)\n","Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (1.15.0)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (0.34.2)\n","Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (1.4.1)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (1.1.2)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (0.9.0)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (1.18.5)\n","Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (0.3.3)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (1.30.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.2.0) (1.1.0)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_gpu==2.2.0) (49.1.0)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (1.17.2)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (1.0.1)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (3.2.2)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (2.23.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (0.4.1)\n","Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (1.7.0)\n","Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (4.6)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (0.2.8)\n","Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (4.1.1)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (1.7.0)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (1.24.3)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (1.3.0)\n","Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (0.4.8)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (3.1.0)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow_gpu==2.2.0) (3.1.0)\n","Installing collected packages: tensorflow-gpu\n","Successfully installed tensorflow-gpu-2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ypWGYdPlLRUN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"ok","timestamp":1596143866270,"user_tz":240,"elapsed":152300,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"3f52e077-fdd2-432a-be02-ee1ced2eea39"},"source":["import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Cloning into 'models'...\n","remote: Enumerating objects: 2800, done.\u001b[K\n","remote: Counting objects: 100% (2800/2800), done.\u001b[K\n","remote: Compressing objects: 100% (2438/2438), done.\u001b[K\n","remote: Total 2800 (delta 569), reused 1405 (delta 326), pack-reused 0\u001b[K\n","Receiving objects: 100% (2800/2800), 57.74 MiB | 3.50 MiB/s, done.\n","Resolving deltas: 100% (569/569), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6QPmVBSlLTzM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1596143899999,"user_tz":240,"elapsed":186020,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"d3363b93-59d6-48ab-c4ab-8b19fcd9d5c1"},"source":["# Install the Object Detection API\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"execution_count":8,"outputs":[{"output_type":"stream","text":["Processing /content/models/research\n","Collecting avro-python3==1.8.1\n","  Downloading https://files.pythonhosted.org/packages/7d/7a/90ff9b8013e21942009380e7b86cf19d3dc83adb7042b735f016ca7e2b68/avro-python3-1.8.1.tar.gz\n","Collecting apache-beam\n","  Downloading https://files.pythonhosted.org/packages/56/f1/7fcfbff3d3eed7895f10b358844b6e8ed21b230666aabd09d842cd725363/apache_beam-2.23.0-cp36-cp36m-manylinux2010_x86_64.whl (8.3MB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.0.5)\n","Collecting tf-models-official\n","  Downloading https://files.pythonhosted.org/packages/99/8e/6db83bab2f86475fa69289848379f642746314131527d8a4ced47a6396af/tf_models_official-2.2.2-py2.py3-none-any.whl (711kB)\n","Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n","Collecting future<1.0.0,>=0.18.2\n","  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","Requirement already satisfied: protobuf<4,>=3.5.0.post1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.12.2)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n","Collecting fastavro<0.24,>=0.21.4\n","  Downloading https://files.pythonhosted.org/packages/98/8e/1d62398df5569a805d956bd96df1b2c06f973e8d3f1f7489adf9c58b2824/fastavro-0.23.6-cp36-cp36m-manylinux2010_x86_64.whl (1.4MB)\n","Collecting oauth2client<4,>=2.0.1\n","  Downloading https://files.pythonhosted.org/packages/c0/7b/bc893e35d6ca46a72faa4b9eaac25c687ce60e1fbe978993fe2de1b0ff0d/oauth2client-3.0.0.tar.gz (77kB)\n","Collecting pyarrow<0.18.0,>=0.15.1; python_version >= \"3.0\" or platform_system != \"Windows\"\n","  Downloading https://files.pythonhosted.org/packages/ba/3f/6cac1714fff444664603f92cb9fbe91c7ae25375880158b9e9691c4584c8/pyarrow-0.17.1-cp36-cp36m-manylinux2014_x86_64.whl (63.8MB)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading https://files.pythonhosted.org/packages/82/39/2c0879b1bcfd1f6ad078eb210d09dbce21072386a3997074ee91e60ddc5a/hdfs-2.5.8.tar.gz (41kB)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n","Collecting mock<3.0.0,>=1.0.1\n","  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.2)\n","Requirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.18.5)\n","Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.10.1)\n","Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.30.0)\n","Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.9.0)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (49.1.0)\n","Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n","Collecting opencv-python-headless\n","  Downloading https://files.pythonhosted.org/packages/17/e4/a98a3c3098ea55b6ae193a1cd19a221dc3c1bde87a36db5550addc879d36/opencv_python_headless-4.3.0.36-cp36-cp36m-manylinux2014_x86_64.whl (36.4MB)\n","Collecting mlperf-compliance==0.0.10\n","  Downloading https://files.pythonhosted.org/packages/f4/08/f2febd8cbd5c9371f7dab311e90400d83238447ba7609b3bf0145b4cb2a2/mlperf_compliance-0.0.10-py3-none-any.whl\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (3.13)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.0)\n","Collecting typing==3.7.4.1\n","  Downloading https://files.pythonhosted.org/packages/fe/2e/b480ee1b75e6d17d2993738670e75c1feeb9ff7f64452153cf018051cc92/typing-3.7.4.1-py3-none-any.whl\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading https://files.pythonhosted.org/packages/f6/f5/8e6e85ce2e9f6e05040cf0d4e26f43a4718bcc4bce988b433276d4b1a5c1/py-cpuinfo-7.0.0.tar.gz (95kB)\n","Collecting sentencepiece\n","  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.3)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.1.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n","Collecting tensorflow-model-optimization>=0.2.1\n","  Downloading https://files.pythonhosted.org/packages/c8/4a/003e16e17c274dd09c81b224b226cdc9902309b905c62a50ebdd0cd12e6d/tensorflow_model_optimization-0.4.0-py2.py3-none-any.whl (169kB)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.7)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.6)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.3.0)\n","Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.2.0)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam->object-detection==0.1) (4.6)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (2.23.0)\n","Collecting pbr>=0.11\n","  Downloading https://files.pythonhosted.org/packages/96/ba/aa953a11ec014b23df057ecdbc922fdb40ca8463466b1193f3367d2711a6/pbr-5.4.5-py2.py3-none-any.whl (110kB)\n","Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.17.2)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.22.2)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (19.3.0)\n","Collecting dm-tree~=0.1.1\n","  Downloading https://files.pythonhosted.org/packages/16/48/10fb721334810081b7e6eebeba0d12e12126c76993e8c243062d2f56a89f/dm_tree-0.1.5-cp36-cp36m-manylinux1_x86_64.whl (294kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (2020.6.20)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.3.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (2.2.2)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (2.10.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.34.2)\n","Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (2.2.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.4.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.1.0)\n","Building wheels for collected packages: object-detection, avro-python3, future, oauth2client, hdfs, dill, py-cpuinfo\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1538690 sha256=eef9e36a6967826d2d0243d04a4f45befbead8f2e8d6e6ed2fdeaa3401095a95\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-3wt0g2ay/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n","  Building wheel for avro-python3 (setup.py): started\n","  Building wheel for avro-python3 (setup.py): finished with status 'done'\n","  Created wheel for avro-python3: filename=avro_python3-1.8.1-cp36-none-any.whl size=43164 sha256=dea5dbcf727ff2667464b0973721426343e58d9743908ba999df8c05456fabff\n","  Stored in directory: /root/.cache/pip/wheels/5c/04/3c/ffe3561c960133e747de503dea3e3facef2dea533bc92cb21a\n","  Building wheel for future (setup.py): started\n","  Building wheel for future (setup.py): finished with status 'done'\n","  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=1521512dd293ad51fee49d0d7d2d344a0cd7e14ebde3485e11ed2a04c0369eb2\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","  Building wheel for oauth2client (setup.py): started\n","  Building wheel for oauth2client (setup.py): finished with status 'done'\n","  Created wheel for oauth2client: filename=oauth2client-3.0.0-cp36-none-any.whl size=106382 sha256=cd67a9ded47e099364adc6ec1f5e96ba6ba15faaa291e54512a39cebcf5a5013\n","  Stored in directory: /root/.cache/pip/wheels/48/f7/87/b932f09c6335dbcf45d916937105a372ab14f353a9ca431d7d\n","  Building wheel for hdfs (setup.py): started\n","  Building wheel for hdfs (setup.py): finished with status 'done'\n","  Created wheel for hdfs: filename=hdfs-2.5.8-cp36-none-any.whl size=33213 sha256=def97c9a0d99e0a4dd6d62f9842da3d635d7204a5ff8fb009bc210de1f446bfa\n","  Stored in directory: /root/.cache/pip/wheels/fe/a7/05/23e3699975fc20f8a30e00ac1e515ab8c61168e982abe4ce70\n","  Building wheel for dill (setup.py): started\n","  Building wheel for dill (setup.py): finished with status 'done'\n","  Created wheel for dill: filename=dill-0.3.1.1-cp36-none-any.whl size=78532 sha256=8036c1ff6f71c8fc6dd4e2e009803c1c7d508e50573f38f596fc326b4271b430\n","  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n","  Building wheel for py-cpuinfo (setup.py): started\n","  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-cp36-none-any.whl size=20069 sha256=0eaf1c5c8bffed6ba867f6a113c993cecdf76be561cf4b2eebe00e463122da4d\n","  Stored in directory: /root/.cache/pip/wheels/f1/93/7b/127daf0c3a5a49feb2fecd468d508067c733fba5192f726ad1\n","Successfully built object-detection avro-python3 future oauth2client hdfs dill py-cpuinfo\n","Installing collected packages: avro-python3, future, fastavro, oauth2client, pyarrow, hdfs, dill, pbr, mock, apache-beam, tf-slim, opencv-python-headless, mlperf-compliance, typing, py-cpuinfo, sentencepiece, dm-tree, tensorflow-model-optimization, tf-models-official, object-detection\n","  Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Found existing installation: oauth2client 4.1.3\n","    Uninstalling oauth2client-4.1.3:\n","      Successfully uninstalled oauth2client-4.1.3\n","  Found existing installation: pyarrow 0.14.1\n","    Uninstalling pyarrow-0.14.1:\n","      Successfully uninstalled pyarrow-0.14.1\n","  Found existing installation: dill 0.3.2\n","    Uninstalling dill-0.3.2:\n","      Successfully uninstalled dill-0.3.2\n","Successfully installed apache-beam-2.23.0 avro-python3-1.8.1 dill-0.3.1.1 dm-tree-0.1.5 fastavro-0.23.6 future-0.18.2 hdfs-2.5.8 mlperf-compliance-0.0.10 mock-2.0.0 oauth2client-3.0.0 object-detection-0.1 opencv-python-headless-4.3.0.36 pbr-5.4.5 py-cpuinfo-7.0.0 pyarrow-0.17.1 sentencepiece-0.1.91 tensorflow-model-optimization-0.4.0 tf-models-official-2.2.2 tf-slim-1.1.0 typing-3.7.4.1\n"],"name":"stdout"},{"output_type":"stream","text":["ERROR: pydrive 1.3.1 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.\n","ERROR: multiprocess 0.70.10 has requirement dill>=0.3.2, but you'll have dill 0.3.1.1 which is incompatible.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6HHXZrSopwri","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1596143901464,"user_tz":240,"elapsed":187476,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"7faba2f2-71bf-4329-d096-b29fd231e144"},"source":["#commence temporary keras fix for exporting efficientDet - this will inevitably be fixed and removed from the notebook in the coming days\n","%cat /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py"],"execution_count":9,"outputs":[{"output_type":"stream","text":["# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","\"\"\"TensorFlow-related utilities.\"\"\"\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import copy\n","import numpy as np\n","import six\n","\n","from tensorflow.python.data.experimental.ops import cardinality\n","from tensorflow.python.eager import context\n","from tensorflow.python.framework import composite_tensor\n","from tensorflow.python.framework import ops\n","from tensorflow.python.framework import smart_cond as smart_module\n","from tensorflow.python.framework import tensor_shape\n","from tensorflow.python.framework import tensor_spec\n","from tensorflow.python.framework import tensor_util\n","from tensorflow.python.framework import type_spec\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.ops import control_flow_ops\n","from tensorflow.python.ops import math_ops\n","from tensorflow.python.ops import variables\n","from tensorflow.python.util import nest\n","from tensorflow.python.util import object_identity\n","from tensorflow.python.util import tf_contextlib\n","\n","\n","def smart_cond(pred, true_fn=None, false_fn=None, name=None):\n","  \"\"\"Return either `true_fn()` if predicate `pred` is true else `false_fn()`.\n","\n","  If `pred` is a bool or has a constant value, we return either `true_fn()`\n","  or `false_fn()`, otherwise we use `tf.cond` to dynamically route to both.\n","\n","  Arguments:\n","    pred: A scalar determining whether to return the result of `true_fn` or\n","      `false_fn`.\n","    true_fn: The callable to be performed if pred is true.\n","    false_fn: The callable to be performed if pred is false.\n","    name: Optional name prefix when using `tf.cond`.\n","\n","  Returns:\n","    Tensors returned by the call to either `true_fn` or `false_fn`.\n","\n","  Raises:\n","    TypeError: If `true_fn` or `false_fn` is not callable.\n","  \"\"\"\n","  if isinstance(pred, variables.Variable):\n","    return control_flow_ops.cond(\n","        pred, true_fn=true_fn, false_fn=false_fn, name=name)\n","  return smart_module.smart_cond(\n","      pred, true_fn=true_fn, false_fn=false_fn, name=name)\n","\n","\n","def constant_value(pred):\n","  \"\"\"Return the bool value for `pred`, or None if `pred` had a dynamic value.\n","\n","  Arguments:\n","    pred: A scalar, either a Python bool or a TensorFlow boolean variable\n","      or tensor, or the Python integer 1 or 0.\n","\n","  Returns:\n","    True or False if `pred` has a constant boolean value, None otherwise.\n","\n","  Raises:\n","    TypeError: If `pred` is not a Variable, Tensor or bool, or Python\n","      integer 1 or 0.\n","  \"\"\"\n","  # Allow integer booleans.\n","  if isinstance(pred, int):\n","    if pred == 1:\n","      pred = True\n","    elif pred == 0:\n","      pred = False\n","\n","  if isinstance(pred, variables.Variable):\n","    return None\n","  return smart_module.smart_constant_value(pred)\n","\n","\n","def is_tensor_or_tensor_list(v):\n","  v = nest.flatten(v)\n","  if v and isinstance(v[0], ops.Tensor):\n","    return True\n","  else:\n","    return False\n","\n","\n","def get_reachable_from_inputs(inputs, targets=None):\n","  \"\"\"Returns the set of tensors/ops reachable from `inputs`.\n","\n","  Stops if all targets have been found (target is optional).\n","\n","  Only valid in Symbolic mode, not Eager mode.\n","\n","  Args:\n","    inputs: List of tensors.\n","    targets: List of tensors.\n","\n","  Returns:\n","    A set of tensors reachable from the inputs (includes the inputs themselves).\n","  \"\"\"\n","  inputs = nest.flatten(inputs, expand_composites=True)\n","  reachable = object_identity.ObjectIdentitySet(inputs)\n","  if targets:\n","    remaining_targets = object_identity.ObjectIdentitySet(nest.flatten(targets))\n","  queue = inputs[:]\n","\n","  while queue:\n","    x = queue.pop()\n","    if isinstance(x, tuple(_user_convertible_tensor_types)):\n","      # Can't find consumers of user-specific types.\n","      continue\n","\n","    if isinstance(x, ops.Operation):\n","      outputs = x.outputs[:] or []\n","      outputs += x._control_outputs  # pylint: disable=protected-access\n","    elif isinstance(x, variables.Variable):\n","      try:\n","        outputs = [x.op]\n","      except AttributeError:\n","        # Variables can be created in an Eager context.\n","        outputs = []\n","    elif tensor_util.is_tensor(x):\n","      outputs = x.consumers()\n","    else:\n","      raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\n","\n","    for y in outputs:\n","      if y not in reachable:\n","        reachable.add(y)\n","        if targets:\n","          remaining_targets.discard(y)\n","        queue.insert(0, y)\n","\n","    if targets and not remaining_targets:\n","      return reachable\n","\n","  return reachable\n","\n","\n","# This function needs access to private functions of `nest`.\n","#  pylint: disable=protected-access\n","def map_structure_with_atomic(is_atomic_fn, map_fn, nested):\n","  \"\"\"Maps the atomic elements of a nested structure.\n","\n","  Arguments:\n","    is_atomic_fn: A function that determines if an element of `nested` is\n","      atomic.\n","    map_fn: The function to apply to atomic elements of `nested`.\n","    nested: A nested structure.\n","\n","  Returns:\n","    The nested structure, with atomic elements mapped according to `map_fn`.\n","\n","  Raises:\n","    ValueError: If an element that is neither atomic nor a sequence is\n","      encountered.\n","  \"\"\"\n","  if is_atomic_fn(nested):\n","    return map_fn(nested)\n","\n","  # Recursively convert.\n","  if not nest.is_sequence(nested):\n","    raise ValueError(\n","        'Received non-atomic and non-sequence element: {}'.format(nested))\n","  if nest._is_mapping(nested):\n","    values = [nested[k] for k in nest._sorted(nested)]\n","  else:\n","    values = nested\n","  mapped_values = [\n","      map_structure_with_atomic(is_atomic_fn, map_fn, ele) for ele in values\n","  ]\n","  return nest._sequence_like(nested, mapped_values)\n","\n","\n","#  pylint: enable=protected-access\n","\n","\n","def convert_shapes(input_shape, to_tuples=True):\n","  \"\"\"Converts nested shape representations to desired format.\n","\n","  Performs:\n","\n","  TensorShapes -> tuples if `to_tuples=True`.\n","  tuples of int or None -> TensorShapes if `to_tuples=False`.\n","\n","  Valid objects to be converted are:\n","  - TensorShapes\n","  - tuples with elements of type int or None.\n","  - ints\n","  - None\n","\n","  Arguments:\n","    input_shape: A nested structure of objects to be converted to TensorShapes.\n","    to_tuples: If `True`, converts all TensorShape to tuples. Otherwise converts\n","      all tuples representing shapes to TensorShapes.\n","\n","  Returns:\n","    Nested structure of shapes in desired format.\n","\n","  Raises:\n","    ValueError: when the input tensor shape can't be converted to tuples, eg\n","      unknown tensor shape.\n","  \"\"\"\n","\n","  def _is_shape_component(value):\n","    return value is None or isinstance(value, (int, tensor_shape.Dimension))\n","\n","  def _is_atomic_shape(input_shape):\n","    # Ex: TensorShape or (None, 10, 32) or 5 or `None`\n","    if _is_shape_component(input_shape):\n","      return True\n","    if isinstance(input_shape, tensor_shape.TensorShape):\n","      return True\n","    if (isinstance(input_shape, (tuple, list)) and\n","        all(_is_shape_component(ele) for ele in input_shape)):\n","      return True\n","    return False\n","\n","  def _convert_shape(input_shape):\n","    input_shape = tensor_shape.TensorShape(input_shape)\n","    if to_tuples:\n","      input_shape = tuple(input_shape.as_list())\n","    return input_shape\n","\n","  return map_structure_with_atomic(_is_atomic_shape, _convert_shape,\n","                                   input_shape)\n","\n","\n","class ListWrapper(object):\n","  \"\"\"A wrapper for lists to be treated as elements for `nest`.\"\"\"\n","\n","  def __init__(self, list_to_wrap):\n","    self._list = list_to_wrap\n","\n","  def as_list(self):\n","    return self._list\n","\n","\n","def convert_inner_node_data(nested, wrap=False):\n","  \"\"\"Either wraps or unwraps innermost node data lists in `ListWrapper` objects.\n","\n","  Arguments:\n","    nested: A nested data structure.\n","    wrap: If `True`, wrap innermost lists in `ListWrapper` objects. If `False`,\n","      unwraps `ListWrapper` objects into lists.\n","\n","  Returns:\n","    Structure of same type as nested, with lists wrapped/unwrapped.\n","  \"\"\"\n","\n","  def _is_serialized_node_data(nested):\n","    # Node data can be of form `[layer_name, node_id, tensor_id]` or\n","    # `[layer_name, node_id, tensor_id, kwargs]`.\n","    if (isinstance(nested, list) and (len(nested) in [3, 4]) and\n","        isinstance(nested[0], six.string_types)):\n","      return True\n","    return False\n","\n","  def _is_atomic_nested(nested):\n","    \"\"\"Returns `True` if `nested` is a list representing node data.\"\"\"\n","    if isinstance(nested, ListWrapper):\n","      return True\n","    if _is_serialized_node_data(nested):\n","      return True\n","    return not nest.is_sequence(nested)\n","\n","  def _convert_object_or_list(nested):\n","    \"\"\"Convert b/t `ListWrapper` object and list representations.\"\"\"\n","    if wrap:\n","      if isinstance(nested, ListWrapper):\n","        return nested\n","      if _is_serialized_node_data(nested):\n","        return ListWrapper(nested)\n","      return nested\n","    else:\n","      if isinstance(nested, ListWrapper):\n","        return nested.as_list()\n","      return nested\n","\n","  return map_structure_with_atomic(_is_atomic_nested, _convert_object_or_list,\n","                                   nested)\n","\n","\n","def shape_type_conversion(fn):\n","  \"\"\"Decorator that handles tuple/TensorShape conversion.\n","\n","  Used in `compute_output_shape` and `build`.\n","\n","  Arguments:\n","    fn: function to wrap.\n","\n","  Returns:\n","    Wrapped function.\n","  \"\"\"\n","\n","  def wrapper(instance, input_shape):\n","    # Pass shapes as tuples to `fn`\n","    # This preserves compatibility with external Keras.\n","    if input_shape is not None:\n","      input_shape = convert_shapes(input_shape, to_tuples=True)\n","    output_shape = fn(instance, input_shape)\n","    # Return shapes from `fn` as TensorShapes.\n","    if output_shape is not None:\n","      output_shape = convert_shapes(output_shape, to_tuples=False)\n","    return output_shape\n","\n","  return wrapper\n","\n","\n","def are_all_symbolic_tensors(tensors):\n","  return all(is_symbolic_tensor(tensor) for tensor in tensors)\n","\n","\n","_user_convertible_tensor_types = set()\n","\n","\n","def is_symbolic_tensor(tensor):\n","  \"\"\"Returns whether a tensor is symbolic (from a TF graph) or an eager tensor.\n","\n","  A Variable can be seen as either: it is considered symbolic\n","  when we are in a graph scope, and eager when we are in an eager scope.\n","\n","  Arguments:\n","    tensor: A tensor instance to test.\n","\n","  Returns:\n","    True for symbolic tensors, False for eager tensors.\n","  \"\"\"\n","  if isinstance(tensor, tuple(_user_convertible_tensor_types)):\n","    tensor = ops.convert_to_tensor_or_composite(tensor)\n","  if isinstance(tensor, variables.Variable):\n","    # Variables that are output of a Keras Layer in Functional API mode\n","    # should be considered symbolic.\n","    # TODO(omalleyt): We need a better way to check this in order to\n","    # enable `run_eagerly=True` for Models containing Layers that\n","    # return Variables as outputs.\n","    return (getattr(tensor, '_keras_history', False) or\n","            not context.executing_eagerly())\n","  if isinstance(tensor, composite_tensor.CompositeTensor):\n","    component_tensors = nest.flatten(tensor, expand_composites=True)\n","    return any(hasattr(t, 'graph') for t in component_tensors)\n","  if isinstance(tensor, ops.Tensor):\n","    return hasattr(tensor, 'graph')\n","  return False\n","\n","\n","def register_symbolic_tensor_type(cls):\n","  \"\"\"Allows users to specify types regarded as symbolic `Tensor`s.\n","\n","  Used in conjunction with `tf.register_tensor_conversion_function`, calling\n","  `tf.keras.utils.register_symbolic_tensor_type(cls)` allows non-`Tensor`\n","  objects to be plumbed through Keras layers.\n","\n","  Example:\n","\n","  ```python\n","  # One-time setup.\n","  class Foo(object):\n","    def __init__(self, input_):\n","      self._input = input_\n","    def value(self):\n","      return tf.constant(42.)\n","\n","  tf.register_tensor_conversion_function(\n","      Foo, lambda x, *args, **kwargs: x.value())\n","\n","  tf.keras.utils.register_symbolic_tensor_type(Foo)\n","\n","  # User-land.\n","  layer = tf.keras.layers.Lambda(lambda input_: Foo(input_))\n","  ```\n","\n","  Arguments:\n","    cls: A `class` type which shall be regarded as a symbolic `Tensor`.\n","  \"\"\"\n","  global _user_convertible_tensor_types\n","  _user_convertible_tensor_types.add(cls)\n","\n","\n","def type_spec_from_value(value):\n","  \"\"\"Grab type_spec without converting array-likes to tensors.\"\"\"\n","  if isinstance(value, composite_tensor.CompositeTensor):\n","    return value._type_spec  # pylint: disable=protected-access\n","  # Get a TensorSpec for array-like data without\n","  # converting the data to a Tensor\n","  if hasattr(value, 'shape') and hasattr(value, 'dtype'):\n","    return tensor_spec.TensorSpec(value.shape, value.dtype)\n","  else:\n","    return type_spec.type_spec_from_value(value)\n","\n","\n","def is_tensor_or_variable(x):\n","  return tensor_util.is_tensor(x) or isinstance(x, variables.Variable)\n","\n","\n","def assert_no_legacy_layers(layers):\n","  \"\"\"Prevent tf.layers.Layers from being used with Keras.\n","\n","  Certain legacy layers inherit from their keras analogs; however they are\n","  not supported with keras and can lead to subtle and hard to diagnose bugs.\n","\n","  Args:\n","    layers: A list of layers to check\n","\n","  Raises:\n","    TypeError: If any elements of layers are tf.layers.Layers\n","  \"\"\"\n","\n","  # isinstance check for tf.layers.Layer introduces a circular dependency.\n","  legacy_layers = [l for l in layers if getattr(l, '_is_legacy_layer', None)]\n","  if legacy_layers:\n","    layer_str = '\\n'.join('  ' + str(l) for l in legacy_layers)\n","    raise TypeError(\n","        'The following are legacy tf.layers.Layers:\\n{}\\nTo use keras as a '\n","        'framework (for instance using the Network, Model, or Sequential '\n","        'classes), please use the tf.keras.layers implementation instead. '\n","        '(Or, if writing custom layers, subclass from tf.keras.layers rather '\n","        'than tf.layers)'.format(layer_str))\n","\n","\n","@tf_contextlib.contextmanager\n","def maybe_init_scope(layer):\n","  \"\"\"Open an `init_scope` if in V2 mode and using the keras graph.\n","\n","  Arguments:\n","    layer: The Layer/Model that is currently active.\n","\n","  Yields:\n","    None\n","  \"\"\"\n","  # Don't open an init_scope in V1 mode or when using legacy tf.layers.\n","  if (ops.executing_eagerly_outside_functions() and\n","      getattr(layer, '_keras_style', True)):\n","    with ops.init_scope():\n","      yield\n","  else:\n","    yield\n","\n","\n","@tf_contextlib.contextmanager\n","def graph_context_for_symbolic_tensors(*args, **kwargs):\n","  \"\"\"Returns graph context manager if any of the inputs is a symbolic tensor.\"\"\"\n","  if any(is_symbolic_tensor(v) for v in list(args) + list(kwargs.values())):\n","    with K.get_graph().as_default():\n","      yield\n","  else:\n","    yield\n","\n","\n","def dataset_is_infinite(dataset):\n","  \"\"\"True if the passed dataset is infinite.\"\"\"\n","  if ops.executing_eagerly_outside_functions():\n","    return math_ops.equal(\n","        cardinality.cardinality(dataset), cardinality.INFINITE)\n","  else:\n","    dataset_size = K.get_session().run(cardinality.cardinality(dataset))\n","    return dataset_size == cardinality.INFINITE\n","\n","\n","def get_tensor_spec(t, dynamic_batch=False, name=None):\n","  \"\"\"Returns a `TensorSpec` given a single `Tensor` or `TensorSpec`.\"\"\"\n","  if isinstance(t, type_spec.TypeSpec):\n","    spec = t\n","  elif isinstance(t, composite_tensor.CompositeTensor):\n","    # TODO(b/148821952): Should these specs have a name attr?\n","    spec = t._type_spec  # pylint: disable=protected-access\n","  elif hasattr(t, 'shape') and hasattr(t, 'dtype'):\n","    spec = tensor_spec.TensorSpec(shape=t.shape, dtype=t.dtype, name=name)\n","  else:\n","    return None  # Allow non-Tensors to pass through.\n","\n","  if not dynamic_batch:\n","    return spec\n","\n","  dynamic_batch_spec = copy.deepcopy(spec)\n","  # RaggedTensorSpec only has a private _shape.\n","  shape = dynamic_batch_spec._shape.as_list()  # pylint: disable=protected-access\n","  if shape:\n","    shape[0] = None\n","    dynamic_batch_spec._shape = tensor_shape.TensorShape(shape)  # pylint: disable=protected-access\n","  return dynamic_batch_spec\n","\n","\n","def to_numpy_or_python_type(tensors):\n","  \"\"\"Converts a structure of `Tensor`s to `NumPy` arrays or Python scalar types.\n","\n","  For each tensor, it calls `tensor.numpy()`. If the result is a scalar value,\n","  it converts it to a Python type, such as a float or int, by calling\n","  `result.item()`.\n","\n","  Numpy scalars are converted, as Python types are often more convenient to deal\n","  with. This is especially useful for bfloat16 Numpy scalars, which don't\n","  support as many operations as other Numpy values.\n","\n","  Args:\n","    tensors: A structure of tensors.\n","\n","  Returns:\n","    `tensors`, but scalar tensors are converted to Python types and non-scalar\n","    tensors are converted to Numpy arrays.\n","  \"\"\"\n","  def _to_single_numpy_or_python_type(t):\n","    if isinstance(t, ops.Tensor):\n","      x = t.numpy()\n","      return x.item() if np.ndim(x) == 0 else x\n","    return t  # Don't turn ragged or sparse tensors to NumPy.\n","\n","  return nest.map_structure(_to_single_numpy_or_python_type, tensors)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OGE37OTsqFdr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1596143901655,"user_tz":240,"elapsed":187657,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"45ad5077-3094-4a46-89c3-2e4a7029761a"},"source":["\n","%%writefile /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\n","\n","\n","#Roboflow: we are making a tiny change to the keras utils so we can export weights!\n","\n","# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","\"\"\"TensorFlow-related utilities.\"\"\"\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import copy\n","import numpy as np\n","import six\n","\n","from tensorflow.python.data.experimental.ops import cardinality\n","from tensorflow.python.eager import context\n","from tensorflow.python.framework import composite_tensor\n","from tensorflow.python.framework import ops\n","from tensorflow.python.framework import smart_cond as smart_module\n","from tensorflow.python.framework import tensor_shape\n","from tensorflow.python.framework import tensor_spec\n","from tensorflow.python.framework import tensor_util\n","from tensorflow.python.framework import type_spec\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.ops import control_flow_ops\n","from tensorflow.python.ops import math_ops\n","from tensorflow.python.ops import variables\n","from tensorflow.python.util import nest\n","from tensorflow.python.util import object_identity\n","from tensorflow.python.util import tf_contextlib\n","\n","\n","def smart_cond(pred, true_fn=None, false_fn=None, name=None):\n","  \"\"\"Return either `true_fn()` if predicate `pred` is true else `false_fn()`.\n","\n","  If `pred` is a bool or has a constant value, we return either `true_fn()`\n","  or `false_fn()`, otherwise we use `tf.cond` to dynamically route to both.\n","\n","  Arguments:\n","    pred: A scalar determining whether to return the result of `true_fn` or\n","      `false_fn`.\n","    true_fn: The callable to be performed if pred is true.\n","    false_fn: The callable to be performed if pred is false.\n","    name: Optional name prefix when using `tf.cond`.\n","\n","  Returns:\n","    Tensors returned by the call to either `true_fn` or `false_fn`.\n","\n","  Raises:\n","    TypeError: If `true_fn` or `false_fn` is not callable.\n","  \"\"\"\n","  if isinstance(pred, variables.Variable):\n","    return control_flow_ops.cond(\n","        pred, true_fn=true_fn, false_fn=false_fn, name=name)\n","  return smart_module.smart_cond(\n","      pred, true_fn=true_fn, false_fn=false_fn, name=name)\n","\n","\n","def constant_value(pred):\n","  \"\"\"Return the bool value for `pred`, or None if `pred` had a dynamic value.\n","\n","  Arguments:\n","    pred: A scalar, either a Python bool or a TensorFlow boolean variable\n","      or tensor, or the Python integer 1 or 0.\n","\n","  Returns:\n","    True or False if `pred` has a constant boolean value, None otherwise.\n","\n","  Raises:\n","    TypeError: If `pred` is not a Variable, Tensor or bool, or Python\n","      integer 1 or 0.\n","  \"\"\"\n","  # Allow integer booleans.\n","  if isinstance(pred, int):\n","    if pred == 1:\n","      pred = True\n","    elif pred == 0:\n","      pred = False\n","\n","  if isinstance(pred, variables.Variable):\n","    return None\n","  return smart_module.smart_constant_value(pred)\n","\n","\n","def is_tensor_or_tensor_list(v):\n","  v = nest.flatten(v)\n","  if v and isinstance(v[0], ops.Tensor):\n","    return True\n","  else:\n","    return False\n","\n","\n","def get_reachable_from_inputs(inputs, targets=None):\n","  \"\"\"Returns the set of tensors/ops reachable from `inputs`.\n","\n","  Stops if all targets have been found (target is optional).\n","\n","  Only valid in Symbolic mode, not Eager mode.\n","\n","  Args:\n","    inputs: List of tensors.\n","    targets: List of tensors.\n","\n","  Returns:\n","    A set of tensors reachable from the inputs (includes the inputs themselves).\n","  \"\"\"\n","  inputs = nest.flatten(inputs, expand_composites=True)\n","  reachable = object_identity.ObjectIdentitySet(inputs)\n","  if targets:\n","    remaining_targets = object_identity.ObjectIdentitySet(nest.flatten(targets))\n","  queue = inputs[:]\n","\n","  while queue:\n","    x = queue.pop()\n","    if isinstance(x, tuple(_user_convertible_tensor_types)):\n","      # Can't find consumers of user-specific types.\n","      continue\n","\n","    if isinstance(x, ops.Operation):\n","      outputs = x.outputs[:] or []\n","      outputs += x._control_outputs  # pylint: disable=protected-access\n","    elif isinstance(x, variables.Variable):\n","      try:\n","        outputs = [x.op]\n","      except AttributeError:\n","        # Variables can be created in an Eager context.\n","        outputs = []\n","    elif tensor_util.is_tensor(x):\n","      outputs = x.consumers()\n","    else:\n","      if not isinstance(x, str):\n","        raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\n","\n","    for y in outputs:\n","      if y not in reachable:\n","        reachable.add(y)\n","        if targets:\n","          remaining_targets.discard(y)\n","        queue.insert(0, y)\n","\n","    if targets and not remaining_targets:\n","      return reachable\n","\n","  return reachable\n","\n","\n","# This function needs access to private functions of `nest`.\n","#  pylint: disable=protected-access\n","def map_structure_with_atomic(is_atomic_fn, map_fn, nested):\n","  \"\"\"Maps the atomic elements of a nested structure.\n","\n","  Arguments:\n","    is_atomic_fn: A function that determines if an element of `nested` is\n","      atomic.\n","    map_fn: The function to apply to atomic elements of `nested`.\n","    nested: A nested structure.\n","\n","  Returns:\n","    The nested structure, with atomic elements mapped according to `map_fn`.\n","\n","  Raises:\n","    ValueError: If an element that is neither atomic nor a sequence is\n","      encountered.\n","  \"\"\"\n","  if is_atomic_fn(nested):\n","    return map_fn(nested)\n","\n","  # Recursively convert.\n","  if not nest.is_sequence(nested):\n","    raise ValueError(\n","        'Received non-atomic and non-sequence element: {}'.format(nested))\n","  if nest._is_mapping(nested):\n","    values = [nested[k] for k in nest._sorted(nested)]\n","  else:\n","    values = nested\n","  mapped_values = [\n","      map_structure_with_atomic(is_atomic_fn, map_fn, ele) for ele in values\n","  ]\n","  return nest._sequence_like(nested, mapped_values)\n","\n","\n","#  pylint: enable=protected-access\n","\n","\n","def convert_shapes(input_shape, to_tuples=True):\n","  \"\"\"Converts nested shape representations to desired format.\n","\n","  Performs:\n","\n","  TensorShapes -> tuples if `to_tuples=True`.\n","  tuples of int or None -> TensorShapes if `to_tuples=False`.\n","\n","  Valid objects to be converted are:\n","  - TensorShapes\n","  - tuples with elements of type int or None.\n","  - ints\n","  - None\n","\n","  Arguments:\n","    input_shape: A nested structure of objects to be converted to TensorShapes.\n","    to_tuples: If `True`, converts all TensorShape to tuples. Otherwise converts\n","      all tuples representing shapes to TensorShapes.\n","\n","  Returns:\n","    Nested structure of shapes in desired format.\n","\n","  Raises:\n","    ValueError: when the input tensor shape can't be converted to tuples, eg\n","      unknown tensor shape.\n","  \"\"\"\n","\n","  def _is_shape_component(value):\n","    return value is None or isinstance(value, (int, tensor_shape.Dimension))\n","\n","  def _is_atomic_shape(input_shape):\n","    # Ex: TensorShape or (None, 10, 32) or 5 or `None`\n","    if _is_shape_component(input_shape):\n","      return True\n","    if isinstance(input_shape, tensor_shape.TensorShape):\n","      return True\n","    if (isinstance(input_shape, (tuple, list)) and\n","        all(_is_shape_component(ele) for ele in input_shape)):\n","      return True\n","    return False\n","\n","  def _convert_shape(input_shape):\n","    input_shape = tensor_shape.TensorShape(input_shape)\n","    if to_tuples:\n","      input_shape = tuple(input_shape.as_list())\n","    return input_shape\n","\n","  return map_structure_with_atomic(_is_atomic_shape, _convert_shape,\n","                                   input_shape)\n","\n","\n","class ListWrapper(object):\n","  \"\"\"A wrapper for lists to be treated as elements for `nest`.\"\"\"\n","\n","  def __init__(self, list_to_wrap):\n","    self._list = list_to_wrap\n","\n","  def as_list(self):\n","    return self._list\n","\n","\n","def convert_inner_node_data(nested, wrap=False):\n","  \"\"\"Either wraps or unwraps innermost node data lists in `ListWrapper` objects.\n","\n","  Arguments:\n","    nested: A nested data structure.\n","    wrap: If `True`, wrap innermost lists in `ListWrapper` objects. If `False`,\n","      unwraps `ListWrapper` objects into lists.\n","\n","  Returns:\n","    Structure of same type as nested, with lists wrapped/unwrapped.\n","  \"\"\"\n","\n","  def _is_serialized_node_data(nested):\n","    # Node data can be of form `[layer_name, node_id, tensor_id]` or\n","    # `[layer_name, node_id, tensor_id, kwargs]`.\n","    if (isinstance(nested, list) and (len(nested) in [3, 4]) and\n","        isinstance(nested[0], six.string_types)):\n","      return True\n","    return False\n","\n","  def _is_atomic_nested(nested):\n","    \"\"\"Returns `True` if `nested` is a list representing node data.\"\"\"\n","    if isinstance(nested, ListWrapper):\n","      return True\n","    if _is_serialized_node_data(nested):\n","      return True\n","    return not nest.is_sequence(nested)\n","\n","  def _convert_object_or_list(nested):\n","    \"\"\"Convert b/t `ListWrapper` object and list representations.\"\"\"\n","    if wrap:\n","      if isinstance(nested, ListWrapper):\n","        return nested\n","      if _is_serialized_node_data(nested):\n","        return ListWrapper(nested)\n","      return nested\n","    else:\n","      if isinstance(nested, ListWrapper):\n","        return nested.as_list()\n","      return nested\n","\n","  return map_structure_with_atomic(_is_atomic_nested, _convert_object_or_list,\n","                                   nested)\n","\n","\n","def shape_type_conversion(fn):\n","  \"\"\"Decorator that handles tuple/TensorShape conversion.\n","\n","  Used in `compute_output_shape` and `build`.\n","\n","  Arguments:\n","    fn: function to wrap.\n","\n","  Returns:\n","    Wrapped function.\n","  \"\"\"\n","\n","  def wrapper(instance, input_shape):\n","    # Pass shapes as tuples to `fn`\n","    # This preserves compatibility with external Keras.\n","    if input_shape is not None:\n","      input_shape = convert_shapes(input_shape, to_tuples=True)\n","    output_shape = fn(instance, input_shape)\n","    # Return shapes from `fn` as TensorShapes.\n","    if output_shape is not None:\n","      output_shape = convert_shapes(output_shape, to_tuples=False)\n","    return output_shape\n","\n","  return wrapper\n","\n","\n","def are_all_symbolic_tensors(tensors):\n","  return all(is_symbolic_tensor(tensor) for tensor in tensors)\n","\n","\n","_user_convertible_tensor_types = set()\n","\n","\n","def is_symbolic_tensor(tensor):\n","  \"\"\"Returns whether a tensor is symbolic (from a TF graph) or an eager tensor.\n","\n","  A Variable can be seen as either: it is considered symbolic\n","  when we are in a graph scope, and eager when we are in an eager scope.\n","\n","  Arguments:\n","    tensor: A tensor instance to test.\n","\n","  Returns:\n","    True for symbolic tensors, False for eager tensors.\n","  \"\"\"\n","  if isinstance(tensor, tuple(_user_convertible_tensor_types)):\n","    tensor = ops.convert_to_tensor_or_composite(tensor)\n","  if isinstance(tensor, variables.Variable):\n","    # Variables that are output of a Keras Layer in Functional API mode\n","    # should be considered symbolic.\n","    # TODO(omalleyt): We need a better way to check this in order to\n","    # enable `run_eagerly=True` for Models containing Layers that\n","    # return Variables as outputs.\n","    return (getattr(tensor, '_keras_history', False) or\n","            not context.executing_eagerly())\n","  if isinstance(tensor, composite_tensor.CompositeTensor):\n","    component_tensors = nest.flatten(tensor, expand_composites=True)\n","    return any(hasattr(t, 'graph') for t in component_tensors)\n","  if isinstance(tensor, ops.Tensor):\n","    return hasattr(tensor, 'graph')\n","  return False\n","\n","\n","def register_symbolic_tensor_type(cls):\n","  \"\"\"Allows users to specify types regarded as symbolic `Tensor`s.\n","\n","  Used in conjunction with `tf.register_tensor_conversion_function`, calling\n","  `tf.keras.utils.register_symbolic_tensor_type(cls)` allows non-`Tensor`\n","  objects to be plumbed through Keras layers.\n","\n","  Example:\n","\n","  ```python\n","  # One-time setup.\n","  class Foo(object):\n","    def __init__(self, input_):\n","      self._input = input_\n","    def value(self):\n","      return tf.constant(42.)\n","\n","  tf.register_tensor_conversion_function(\n","      Foo, lambda x, *args, **kwargs: x.value())\n","\n","  tf.keras.utils.register_symbolic_tensor_type(Foo)\n","\n","  # User-land.\n","  layer = tf.keras.layers.Lambda(lambda input_: Foo(input_))\n","  ```\n","\n","  Arguments:\n","    cls: A `class` type which shall be regarded as a symbolic `Tensor`.\n","  \"\"\"\n","  global _user_convertible_tensor_types\n","  _user_convertible_tensor_types.add(cls)\n","\n","\n","def type_spec_from_value(value):\n","  \"\"\"Grab type_spec without converting array-likes to tensors.\"\"\"\n","  if isinstance(value, composite_tensor.CompositeTensor):\n","    return value._type_spec  # pylint: disable=protected-access\n","  # Get a TensorSpec for array-like data without\n","  # converting the data to a Tensor\n","  if hasattr(value, 'shape') and hasattr(value, 'dtype'):\n","    return tensor_spec.TensorSpec(value.shape, value.dtype)\n","  else:\n","    return type_spec.type_spec_from_value(value)\n","\n","\n","def is_tensor_or_variable(x):\n","  return tensor_util.is_tensor(x) or isinstance(x, variables.Variable)\n","\n","\n","def assert_no_legacy_layers(layers):\n","  \"\"\"Prevent tf.layers.Layers from being used with Keras.\n","\n","  Certain legacy layers inherit from their keras analogs; however they are\n","  not supported with keras and can lead to subtle and hard to diagnose bugs.\n","\n","  Args:\n","    layers: A list of layers to check\n","\n","  Raises:\n","    TypeError: If any elements of layers are tf.layers.Layers\n","  \"\"\"\n","\n","  # isinstance check for tf.layers.Layer introduces a circular dependency.\n","  legacy_layers = [l for l in layers if getattr(l, '_is_legacy_layer', None)]\n","  if legacy_layers:\n","    layer_str = '\\n'.join('  ' + str(l) for l in legacy_layers)\n","    raise TypeError(\n","        'The following are legacy tf.layers.Layers:\\n{}\\nTo use keras as a '\n","        'framework (for instance using the Network, Model, or Sequential '\n","        'classes), please use the tf.keras.layers implementation instead. '\n","        '(Or, if writing custom layers, subclass from tf.keras.layers rather '\n","        'than tf.layers)'.format(layer_str))\n","\n","\n","@tf_contextlib.contextmanager\n","def maybe_init_scope(layer):\n","  \"\"\"Open an `init_scope` if in V2 mode and using the keras graph.\n","\n","  Arguments:\n","    layer: The Layer/Model that is currently active.\n","\n","  Yields:\n","    None\n","  \"\"\"\n","  # Don't open an init_scope in V1 mode or when using legacy tf.layers.\n","  if (ops.executing_eagerly_outside_functions() and\n","      getattr(layer, '_keras_style', True)):\n","    with ops.init_scope():\n","      yield\n","  else:\n","    yield\n","\n","\n","@tf_contextlib.contextmanager\n","def graph_context_for_symbolic_tensors(*args, **kwargs):\n","  \"\"\"Returns graph context manager if any of the inputs is a symbolic tensor.\"\"\"\n","  if any(is_symbolic_tensor(v) for v in list(args) + list(kwargs.values())):\n","    with K.get_graph().as_default():\n","      yield\n","  else:\n","    yield\n","\n","\n","def dataset_is_infinite(dataset):\n","  \"\"\"True if the passed dataset is infinite.\"\"\"\n","  if ops.executing_eagerly_outside_functions():\n","    return math_ops.equal(\n","        cardinality.cardinality(dataset), cardinality.INFINITE)\n","  else:\n","    dataset_size = K.get_session().run(cardinality.cardinality(dataset))\n","    return dataset_size == cardinality.INFINITE\n","\n","\n","def get_tensor_spec(t, dynamic_batch=False, name=None):\n","  \"\"\"Returns a `TensorSpec` given a single `Tensor` or `TensorSpec`.\"\"\"\n","  if isinstance(t, type_spec.TypeSpec):\n","    spec = t\n","  elif isinstance(t, composite_tensor.CompositeTensor):\n","    # TODO(b/148821952): Should these specs have a name attr?\n","    spec = t._type_spec  # pylint: disable=protected-access\n","  elif hasattr(t, 'shape') and hasattr(t, 'dtype'):\n","    spec = tensor_spec.TensorSpec(shape=t.shape, dtype=t.dtype, name=name)\n","  else:\n","    return None  # Allow non-Tensors to pass through.\n","\n","  if not dynamic_batch:\n","    return spec\n","\n","  dynamic_batch_spec = copy.deepcopy(spec)\n","  # RaggedTensorSpec only has a private _shape.\n","  shape = dynamic_batch_spec._shape.as_list()  # pylint: disable=protected-access\n","  if shape:\n","    shape[0] = None\n","    dynamic_batch_spec._shape = tensor_shape.TensorShape(shape)  # pylint: disable=protected-access\n","  return dynamic_batch_spec\n","\n","\n","def to_numpy_or_python_type(tensors):\n","  \"\"\"Converts a structure of `Tensor`s to `NumPy` arrays or Python scalar types.\n","\n","  For each tensor, it calls `tensor.numpy()`. If the result is a scalar value,\n","  it converts it to a Python type, such as a float or int, by calling\n","  `result.item()`.\n","\n","  Numpy scalars are converted, as Python types are often more convenient to deal\n","  with. This is especially useful for bfloat16 Numpy scalars, which don't\n","  support as many operations as other Numpy values.\n","\n","  Args:\n","    tensors: A structure of tensors.\n","\n","  Returns:\n","    `tensors`, but scalar tensors are converted to Python types and non-scalar\n","    tensors are converted to Numpy arrays.\n","  \"\"\"\n","  def _to_single_numpy_or_python_type(t):\n","    if isinstance(t, ops.Tensor):\n","      x = t.numpy()\n","      return x.item() if np.ndim(x) == 0 else x\n","    return t  # Don't turn ragged or sparse tensors to NumPy.\n","\n","  return nest.map_structure(_to_single_numpy_or_python_type, tensors)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Overwriting /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wHfsJ5nWLWh9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596143903518,"user_tz":240,"elapsed":189516,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import os\n","import random\n","import io\n","import imageio\n","import glob\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from IPython.display import display, Javascript\n","from IPython.display import Image as IPyImage\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.utils import colab_utils\n","from object_detection.builders import model_builder\n","\n","%matplotlib inline"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"wh_HPMOqWH9z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1596143968051,"user_tz":240,"elapsed":254041,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"2034f378-9a63-4e5b-ed45-a39b149556a1"},"source":["#run model builder test\n","!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Running tests under Python 3.6.9: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n","2020-07-30 21:18:26.285947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-07-30 21:18:26.347307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-30 21:18:26.347936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n","2020-07-30 21:18:26.348259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-30 21:18:26.619873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-30 21:18:26.738649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-30 21:18:26.769324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-30 21:18:27.032982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-30 21:18:27.083790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-30 21:18:27.602348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-30 21:18:27.602566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-30 21:18:27.603332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-30 21:18:27.603973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n","2020-07-30 21:18:27.604428: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2020-07-30 21:18:27.609910: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2000134999 Hz\n","2020-07-30 21:18:27.610145: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f90d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-07-30 21:18:27.610195: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-07-30 21:18:27.749335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-30 21:18:27.750059: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f90bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-07-30 21:18:27.750093: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-07-30 21:18:27.751580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-30 21:18:27.752177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n","2020-07-30 21:18:27.752252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-30 21:18:27.752283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-30 21:18:27.752319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-30 21:18:27.752345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-30 21:18:27.752368: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-30 21:18:27.752391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-30 21:18:27.752423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-30 21:18:27.752503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-30 21:18:27.753114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-30 21:18:27.753647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n","2020-07-30 21:18:27.753754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-30 21:18:27.755136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-07-30 21:18:27.755169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n","2020-07-30 21:18:27.755181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n","2020-07-30 21:18:27.755297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-30 21:18:27.755890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-30 21:18:27.756450: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-07-30 21:18:27.756530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14071 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0730 21:18:37.049292 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0730 21:18:37.049477 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n","I0730 21:18:37.049553 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n","I0730 21:18:37.057438 140389092697984 efficientnet_model.py:146] round_filter input=32 output=32\n","I0730 21:18:37.097325 140389092697984 efficientnet_model.py:146] round_filter input=32 output=32\n","I0730 21:18:37.097460 140389092697984 efficientnet_model.py:146] round_filter input=16 output=16\n","I0730 21:18:37.213775 140389092697984 efficientnet_model.py:146] round_filter input=16 output=16\n","I0730 21:18:37.213931 140389092697984 efficientnet_model.py:146] round_filter input=24 output=24\n","I0730 21:18:37.536587 140389092697984 efficientnet_model.py:146] round_filter input=24 output=24\n","I0730 21:18:37.536762 140389092697984 efficientnet_model.py:146] round_filter input=40 output=40\n","I0730 21:18:37.851539 140389092697984 efficientnet_model.py:146] round_filter input=40 output=40\n","I0730 21:18:37.851707 140389092697984 efficientnet_model.py:146] round_filter input=80 output=80\n","I0730 21:18:38.338458 140389092697984 efficientnet_model.py:146] round_filter input=80 output=80\n","I0730 21:18:38.338654 140389092697984 efficientnet_model.py:146] round_filter input=112 output=112\n","I0730 21:18:38.818590 140389092697984 efficientnet_model.py:146] round_filter input=112 output=112\n","I0730 21:18:38.818770 140389092697984 efficientnet_model.py:146] round_filter input=192 output=192\n","I0730 21:18:39.621561 140389092697984 efficientnet_model.py:146] round_filter input=192 output=192\n","I0730 21:18:39.621778 140389092697984 efficientnet_model.py:146] round_filter input=320 output=320\n","I0730 21:18:39.782284 140389092697984 efficientnet_model.py:146] round_filter input=1280 output=1280\n","I0730 21:18:39.841966 140389092697984 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0730 21:18:39.931385 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0730 21:18:39.931550 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 88\n","I0730 21:18:39.931630 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 4\n","I0730 21:18:39.938524 140389092697984 efficientnet_model.py:146] round_filter input=32 output=32\n","I0730 21:18:39.977683 140389092697984 efficientnet_model.py:146] round_filter input=32 output=32\n","I0730 21:18:39.977808 140389092697984 efficientnet_model.py:146] round_filter input=16 output=16\n","I0730 21:18:40.215174 140389092697984 efficientnet_model.py:146] round_filter input=16 output=16\n","I0730 21:18:40.215340 140389092697984 efficientnet_model.py:146] round_filter input=24 output=24\n","I0730 21:18:40.703649 140389092697984 efficientnet_model.py:146] round_filter input=24 output=24\n","I0730 21:18:40.703817 140389092697984 efficientnet_model.py:146] round_filter input=40 output=40\n","I0730 21:18:41.184434 140389092697984 efficientnet_model.py:146] round_filter input=40 output=40\n","I0730 21:18:41.184603 140389092697984 efficientnet_model.py:146] round_filter input=80 output=80\n","I0730 21:18:41.855157 140389092697984 efficientnet_model.py:146] round_filter input=80 output=80\n","I0730 21:18:41.855337 140389092697984 efficientnet_model.py:146] round_filter input=112 output=112\n","I0730 21:18:42.516823 140389092697984 efficientnet_model.py:146] round_filter input=112 output=112\n","I0730 21:18:42.517006 140389092697984 efficientnet_model.py:146] round_filter input=192 output=192\n","I0730 21:18:43.331957 140389092697984 efficientnet_model.py:146] round_filter input=192 output=192\n","I0730 21:18:43.332142 140389092697984 efficientnet_model.py:146] round_filter input=320 output=320\n","I0730 21:18:43.649262 140389092697984 efficientnet_model.py:146] round_filter input=1280 output=1280\n","I0730 21:18:43.710751 140389092697984 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0730 21:18:44.006547 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0730 21:18:44.006731 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 112\n","I0730 21:18:44.006812 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 5\n","I0730 21:18:44.013710 140389092697984 efficientnet_model.py:146] round_filter input=32 output=32\n","I0730 21:18:44.053922 140389092697984 efficientnet_model.py:146] round_filter input=32 output=32\n","I0730 21:18:44.054080 140389092697984 efficientnet_model.py:146] round_filter input=16 output=16\n","I0730 21:18:44.303804 140389092697984 efficientnet_model.py:146] round_filter input=16 output=16\n","I0730 21:18:44.304001 140389092697984 efficientnet_model.py:146] round_filter input=24 output=24\n","I0730 21:18:44.792348 140389092697984 efficientnet_model.py:146] round_filter input=24 output=24\n","I0730 21:18:44.792520 140389092697984 efficientnet_model.py:146] round_filter input=40 output=48\n","I0730 21:18:45.269546 140389092697984 efficientnet_model.py:146] round_filter input=40 output=48\n","I0730 21:18:45.269726 140389092697984 efficientnet_model.py:146] round_filter input=80 output=88\n","I0730 21:18:45.923344 140389092697984 efficientnet_model.py:146] round_filter input=80 output=88\n","I0730 21:18:45.923515 140389092697984 efficientnet_model.py:146] round_filter input=112 output=120\n","I0730 21:18:46.578582 140389092697984 efficientnet_model.py:146] round_filter input=112 output=120\n","I0730 21:18:46.578752 140389092697984 efficientnet_model.py:146] round_filter input=192 output=208\n","I0730 21:18:47.405716 140389092697984 efficientnet_model.py:146] round_filter input=192 output=208\n","I0730 21:18:47.405891 140389092697984 efficientnet_model.py:146] round_filter input=320 output=352\n","I0730 21:18:47.729599 140389092697984 efficientnet_model.py:146] round_filter input=1280 output=1408\n","I0730 21:18:47.789694 140389092697984 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0730 21:18:47.892855 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0730 21:18:47.893007 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 160\n","I0730 21:18:47.893139 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 6\n","I0730 21:18:47.899531 140389092697984 efficientnet_model.py:146] round_filter input=32 output=40\n","I0730 21:18:47.939367 140389092697984 efficientnet_model.py:146] round_filter input=32 output=40\n","I0730 21:18:47.939513 140389092697984 efficientnet_model.py:146] round_filter input=16 output=24\n","I0730 21:18:48.191702 140389092697984 efficientnet_model.py:146] round_filter input=16 output=24\n","I0730 21:18:48.191874 140389092697984 efficientnet_model.py:146] round_filter input=24 output=32\n","I0730 21:18:48.697232 140389092697984 efficientnet_model.py:146] round_filter input=24 output=32\n","I0730 21:18:48.697402 140389092697984 efficientnet_model.py:146] round_filter input=40 output=48\n","I0730 21:18:49.179394 140389092697984 efficientnet_model.py:146] round_filter input=40 output=48\n","I0730 21:18:49.179588 140389092697984 efficientnet_model.py:146] round_filter input=80 output=96\n","I0730 21:18:50.261646 140389092697984 efficientnet_model.py:146] round_filter input=80 output=96\n","I0730 21:18:50.261835 140389092697984 efficientnet_model.py:146] round_filter input=112 output=136\n","I0730 21:18:51.090301 140389092697984 efficientnet_model.py:146] round_filter input=112 output=136\n","I0730 21:18:51.090480 140389092697984 efficientnet_model.py:146] round_filter input=192 output=232\n","I0730 21:18:52.085046 140389092697984 efficientnet_model.py:146] round_filter input=192 output=232\n","I0730 21:18:52.085229 140389092697984 efficientnet_model.py:146] round_filter input=320 output=384\n","I0730 21:18:52.408998 140389092697984 efficientnet_model.py:146] round_filter input=1280 output=1536\n","I0730 21:18:52.469928 140389092697984 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0730 21:18:52.577486 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0730 21:18:52.577649 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 224\n","I0730 21:18:52.577730 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n","I0730 21:18:52.584304 140389092697984 efficientnet_model.py:146] round_filter input=32 output=48\n","I0730 21:18:52.625951 140389092697984 efficientnet_model.py:146] round_filter input=32 output=48\n","I0730 21:18:52.626110 140389092697984 efficientnet_model.py:146] round_filter input=16 output=24\n","I0730 21:18:52.877039 140389092697984 efficientnet_model.py:146] round_filter input=16 output=24\n","I0730 21:18:52.877208 140389092697984 efficientnet_model.py:146] round_filter input=24 output=32\n","I0730 21:18:53.546873 140389092697984 efficientnet_model.py:146] round_filter input=24 output=32\n","I0730 21:18:53.547118 140389092697984 efficientnet_model.py:146] round_filter input=40 output=56\n","I0730 21:18:54.212211 140389092697984 efficientnet_model.py:146] round_filter input=40 output=56\n","I0730 21:18:54.212376 140389092697984 efficientnet_model.py:146] round_filter input=80 output=112\n","I0730 21:18:55.214109 140389092697984 efficientnet_model.py:146] round_filter input=80 output=112\n","I0730 21:18:55.214278 140389092697984 efficientnet_model.py:146] round_filter input=112 output=160\n","I0730 21:18:56.220946 140389092697984 efficientnet_model.py:146] round_filter input=112 output=160\n","I0730 21:18:56.221158 140389092697984 efficientnet_model.py:146] round_filter input=192 output=272\n","I0730 21:18:57.863394 140389092697984 efficientnet_model.py:146] round_filter input=192 output=272\n","I0730 21:18:57.863569 140389092697984 efficientnet_model.py:146] round_filter input=320 output=448\n","I0730 21:18:58.186580 140389092697984 efficientnet_model.py:146] round_filter input=1280 output=1792\n","I0730 21:18:58.249144 140389092697984 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0730 21:18:58.380923 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0730 21:18:58.381115 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 288\n","I0730 21:18:58.381203 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n","I0730 21:18:58.388228 140389092697984 efficientnet_model.py:146] round_filter input=32 output=48\n","I0730 21:18:58.431195 140389092697984 efficientnet_model.py:146] round_filter input=32 output=48\n","I0730 21:18:58.431355 140389092697984 efficientnet_model.py:146] round_filter input=16 output=24\n","I0730 21:18:58.844535 140389092697984 efficientnet_model.py:146] round_filter input=16 output=24\n","I0730 21:18:58.844722 140389092697984 efficientnet_model.py:146] round_filter input=24 output=40\n","I0730 21:18:59.716606 140389092697984 efficientnet_model.py:146] round_filter input=24 output=40\n","I0730 21:18:59.716781 140389092697984 efficientnet_model.py:146] round_filter input=40 output=64\n","I0730 21:19:00.579173 140389092697984 efficientnet_model.py:146] round_filter input=40 output=64\n","I0730 21:19:00.579362 140389092697984 efficientnet_model.py:146] round_filter input=80 output=128\n","I0730 21:19:01.747870 140389092697984 efficientnet_model.py:146] round_filter input=80 output=128\n","I0730 21:19:01.748059 140389092697984 efficientnet_model.py:146] round_filter input=112 output=176\n","I0730 21:19:02.980185 140389092697984 efficientnet_model.py:146] round_filter input=112 output=176\n","I0730 21:19:02.980364 140389092697984 efficientnet_model.py:146] round_filter input=192 output=304\n","I0730 21:19:04.576969 140389092697984 efficientnet_model.py:146] round_filter input=192 output=304\n","I0730 21:19:04.577159 140389092697984 efficientnet_model.py:146] round_filter input=320 output=512\n","I0730 21:19:05.113575 140389092697984 efficientnet_model.py:146] round_filter input=1280 output=2048\n","I0730 21:19:05.178755 140389092697984 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0730 21:19:05.707769 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0730 21:19:05.707949 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n","I0730 21:19:05.708065 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n","I0730 21:19:05.714892 140389092697984 efficientnet_model.py:146] round_filter input=32 output=56\n","I0730 21:19:05.759130 140389092697984 efficientnet_model.py:146] round_filter input=32 output=56\n","I0730 21:19:05.759264 140389092697984 efficientnet_model.py:146] round_filter input=16 output=32\n","I0730 21:19:06.162889 140389092697984 efficientnet_model.py:146] round_filter input=16 output=32\n","I0730 21:19:06.163104 140389092697984 efficientnet_model.py:146] round_filter input=24 output=40\n","I0730 21:19:07.233491 140389092697984 efficientnet_model.py:146] round_filter input=24 output=40\n","I0730 21:19:07.233682 140389092697984 efficientnet_model.py:146] round_filter input=40 output=72\n","I0730 21:19:08.314782 140389092697984 efficientnet_model.py:146] round_filter input=40 output=72\n","I0730 21:19:08.314964 140389092697984 efficientnet_model.py:146] round_filter input=80 output=144\n","I0730 21:19:09.767645 140389092697984 efficientnet_model.py:146] round_filter input=80 output=144\n","I0730 21:19:09.767822 140389092697984 efficientnet_model.py:146] round_filter input=112 output=200\n","I0730 21:19:11.235935 140389092697984 efficientnet_model.py:146] round_filter input=112 output=200\n","I0730 21:19:11.236123 140389092697984 efficientnet_model.py:146] round_filter input=192 output=344\n","I0730 21:19:13.224725 140389092697984 efficientnet_model.py:146] round_filter input=192 output=344\n","I0730 21:19:13.224898 140389092697984 efficientnet_model.py:146] round_filter input=320 output=576\n","I0730 21:19:13.751257 140389092697984 efficientnet_model.py:146] round_filter input=1280 output=2304\n","I0730 21:19:13.813912 140389092697984 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0730 21:19:13.978320 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0730 21:19:13.978489 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n","I0730 21:19:13.978565 140389092697984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n","I0730 21:19:13.985641 140389092697984 efficientnet_model.py:146] round_filter input=32 output=64\n","I0730 21:19:14.030904 140389092697984 efficientnet_model.py:146] round_filter input=32 output=64\n","I0730 21:19:14.031089 140389092697984 efficientnet_model.py:146] round_filter input=16 output=32\n","I0730 21:19:14.563245 140389092697984 efficientnet_model.py:146] round_filter input=16 output=32\n","I0730 21:19:14.563415 140389092697984 efficientnet_model.py:146] round_filter input=24 output=48\n","I0730 21:19:15.802974 140389092697984 efficientnet_model.py:146] round_filter input=24 output=48\n","I0730 21:19:15.803166 140389092697984 efficientnet_model.py:146] round_filter input=40 output=80\n","I0730 21:19:17.515340 140389092697984 efficientnet_model.py:146] round_filter input=40 output=80\n","I0730 21:19:17.515513 140389092697984 efficientnet_model.py:146] round_filter input=80 output=160\n","I0730 21:19:19.322196 140389092697984 efficientnet_model.py:146] round_filter input=80 output=160\n","I0730 21:19:19.322370 140389092697984 efficientnet_model.py:146] round_filter input=112 output=224\n","I0730 21:19:21.133384 140389092697984 efficientnet_model.py:146] round_filter input=112 output=224\n","I0730 21:19:21.133578 140389092697984 efficientnet_model.py:146] round_filter input=192 output=384\n","I0730 21:19:23.493360 140389092697984 efficientnet_model.py:146] round_filter input=192 output=384\n","I0730 21:19:23.493546 140389092697984 efficientnet_model.py:146] round_filter input=320 output=640\n","I0730 21:19:24.258702 140389092697984 efficientnet_model.py:146] round_filter input=1280 output=2560\n","I0730 21:19:24.325922 140389092697984 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 20 tests in 58.476s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VA7Zbo3RLt3W","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596143968771,"user_tz":240,"elapsed":254757,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: a file path.\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)\n","\n","def plot_detections(image_np,\n","                    boxes,\n","                    classes,\n","                    scores,\n","                    category_index,\n","                    figsize=(12, 16),\n","                    image_name=None):\n","  \"\"\"Wrapper function to visualize detections.\n","\n","  Args:\n","    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n","    boxes: a numpy array of shape [N, 4]\n","    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n","      and match the keys in the label map.\n","    scores: a numpy array of shape [N] or None.  If scores=None, then\n","      this function assumes that the boxes to be plotted are groundtruth\n","      boxes and plot all boxes as black with no classes or scores.\n","    category_index: a dict containing category dictionaries (each holding\n","      category index `id` and category name `name`) keyed by category indices.\n","    figsize: size for the figure.\n","    image_name: a name for the image file.\n","  \"\"\"\n","  image_np_with_annotations = image_np.copy()\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_annotations,\n","      boxes,\n","      classes,\n","      scores,\n","      category_index,\n","      use_normalized_coordinates=True,\n","      min_score_thresh=0.8)\n","  if image_name:\n","    plt.imsave(image_name, image_np_with_annotations)\n","  else:\n","    plt.imshow(image_np_with_annotations)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2MAcgJ53STW","colab_type":"text"},"source":["# Configure Custom TensorFlow2 Object Detection Training Configuration\n","\n","\n","\n","\n","> In this section you can specify any model in the [TF2 OD model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) and set up your training configuration.\n","\n"]},{"cell_type":"code","metadata":{"id":"gN0EUEa3e5Un","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596143968772,"user_tz":240,"elapsed":254755,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["##change chosen model to deploy different models available in the TF2 object detection zoo\n","MODELS_CONFIG = {\n","    'efficientdet-d0': {\n","        'model_name': 'efficientdet_d0_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n","        'batch_size': 8\n","    },\n","    'efficientdet-d1': {\n","        'model_name': 'efficientdet_d1_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n","        'batch_size': 8\n","    },\n","    'efficientdet-d2': {\n","        'model_name': 'efficientdet_d2_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n","        'batch_size': 8\n","    },\n","        'efficientdet-d3': {\n","        'model_name': 'efficientdet_d3_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n","        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n","        'batch_size': 8\n","    }\n","}\n","\n","#in this tutorial we implement the lightweight, smallest state of the art efficientdet model\n","#if you want to scale up tot larger efficientdet models you will likely need more compute!\n","\n","\n","\n","\n","model_name = MODELS_CONFIG[chosen_model]['model_name']\n","pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n","base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n","#batch_size = MODELS_CONFIG[chosen_model][batch_size] #if you can fit a large batch in memory, it may speed up your training"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"kG4TmJUVrYQ7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":230},"executionInfo":{"status":"ok","timestamp":1596143973214,"user_tz":240,"elapsed":259190,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"9d55702f-ad22-4769-b0e9-b89182bfdab7"},"source":["#download pretrained weights\n","%mkdir /content/models/research/deploy/\n","%cd /content/models/research/deploy/\n","import tarfile\n","download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n","\n","!wget {download_tar}\n","tar = tarfile.open(pretrained_checkpoint)\n","tar.extractall()\n","tar.close()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/content/models/research/deploy\n","--2020-07-30 21:19:30--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.119.128, 2a00:1450:4013:c00::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.119.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30736482 (29M) [application/x-tar]\n","Saving to: ‘efficientdet_d0_coco17_tpu-32.tar.gz’\n","\n","efficientdet_d0_coc 100%[===================>]  29.31M  60.1MB/s    in 0.5s    \n","\n","2020-07-30 21:19:31 (60.1 MB/s) - ‘efficientdet_d0_coco17_tpu-32.tar.gz’ saved [30736482/30736482]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c-nqYZtdtsgG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":230},"executionInfo":{"status":"ok","timestamp":1596143975274,"user_tz":240,"elapsed":261244,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"c1d31a81-f7ba-48de-aead-fd48a8a36b7f"},"source":["#download base training configuration file\n","%cd /content/models/research/deploy\n","download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n","!wget {download_config}"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/content/models/research/deploy\n","--2020-07-30 21:19:33--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4630 (4.5K) [text/plain]\n","Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’\n","\n","ssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0s      \n","\n","2020-07-30 21:19:33 (62.8 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’ saved [4630/4630]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b_ki9jOqxn7V","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596143976108,"user_tz":240,"elapsed":262074,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["#prepare\n","pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n","fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n","\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eA5ht3_yukT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":274},"executionInfo":{"status":"error","timestamp":1596143976565,"user_tz":240,"elapsed":262525,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}},"outputId":"1a701435-465f-4383-b45c-8fcb48057a3a"},"source":["#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n","\n","import re\n","\n","%cd /content/models/research/deploy\n","print('writing custom configuration file')\n","\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open('pipeline_file.config', 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    \n","    #fine-tune checkpoint type\n","    s = re.sub(\n","        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n","        \n","    f.write(s)\n","\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["/content/models/research/deploy\n","writing custom configuration file\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-0158b91d9b00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n\u001b[1;32m     19\u001b[0m     s = re.sub(\n\u001b[0;32m---> 20\u001b[0;31m         '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# label_map_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_record_fname' is not defined"]}]},{"cell_type":"code","metadata":{"id":"HEsOLOMHzBqF","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976549,"user_tz":240,"elapsed":262503,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["%cat /content/models/research/deploy/pipeline_file.config\n","#cp /content/models/research/deploy/pipeline_file.config "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMlaN3rs3zLe","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976552,"user_tz":240,"elapsed":262502,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XxPj_QV43qD5","colab_type":"text"},"source":["# Train Custom TF2 Object Detector\n","\n","* pipeline_file: defined above in writing custom training configuration\n","* model_dir: the location tensorboard logs and saved model checkpoints will save to\n","* num_train_steps: how long to train for\n","* num_eval_steps: perform eval on validation set after this many steps\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"tQTfZChVzzpZ","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976553,"user_tz":240,"elapsed":262495,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1 \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9KNv1N_hUibE","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976554,"user_tz":240,"elapsed":262491,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["#run model evaluation to obtain performance metrics\n","#!python /content/models/research/object_detection/model_main_tf2.py \\\n","    #--pipeline_config_path={pipeline_file} \\\n","    #--model_dir={model_dir} \\\n","    #--checkpoint_dir={model_dir} \\\n","#Not yet implemented for EfficientDet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TI9iCCxoNlAL","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976555,"user_tz":240,"elapsed":262489,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["%load_ext tensorboard\n","tensorboard_train_path = model_dir + '/train'\n","%tensorboard --logdir $tensorboard_train_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXZ5RxipUhWF","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976555,"user_tz":240,"elapsed":262486,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Vk2146Ogil3","colab_type":"text"},"source":["## Exporting a Trained Inference Graph\n","Still to come for TF2 models, we will be updating this Colab notebook accordingly as the functionality is added. "]},{"cell_type":"code","metadata":{"id":"vqaZ4v-vIuDl","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976556,"user_tz":240,"elapsed":262484,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["#see where our model saved weights\n","%ls $model_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YnSEZIzl4M10","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976557,"user_tz":240,"elapsed":262482,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["#run conversion script\n","import re\n","import numpy as np\n","\n","output_directory = '/content/fine_tuned_model'\n","\n","#place the model weights you would like to export here\n","last_model_path = model_dir #'/content/training/'\n","print(last_model_path)\n","!python /content/models/research/object_detection/exporter_main_v2.py \\\n","    --trained_checkpoint_dir {last_model_path} \\\n","    --output_directory {output_directory} \\\n","    --pipeline_config_path {pipeline_file}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TsE_uVjlsz3u","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976557,"user_tz":240,"elapsed":262479,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["%ls '/content/fine_tuned_model/saved_model/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Vz2vJeCCyZR","colab_type":"text"},"source":["# Run Inference on Test Images with Custom TensorFlow2 Object Detector"]},{"cell_type":"code","metadata":{"id":"xxtm1NutE5vK","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976560,"user_tz":240,"elapsed":262479,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import io\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qs1HJnEhyevJ","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976560,"user_tz":240,"elapsed":262477,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: the file path to the image\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0f6DTolSDfXs","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976562,"user_tz":240,"elapsed":262476,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["%ls $model_dir #'/content/training/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFY75DfTDHaU","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976563,"user_tz":240,"elapsed":262474,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["#recover our saved model\n","pipeline_config = pipeline_file\n","#generally you want to put the last ckpt from training in here\n","ckpt_dir = model__dir + '/ckpt-1'  #'/content/training/ckpt-2'\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n","model_config = configs['model']\n","detection_model = model_builder.build(\n","  model_config=model_config, is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(\n","model=detection_model)\n","ckpt.restore(ckpt_dir)\n","\n","\n","def get_model_detection_function(model):\n","  \"\"\"Get a tf.function for detection.\"\"\"\n","\n","  @tf.function\n","  def detect_fn(image):\n","    \"\"\"Detect objects in image.\"\"\"\n","\n","    image, shapes = model.preprocess(image)\n","    prediction_dict = model.predict(image, shapes)\n","    detections = model.postprocess(prediction_dict, shapes)\n","\n","    return detections, prediction_dict, tf.reshape(shapes, [-1])\n","\n","  return detect_fn\n","\n","detect_fn = get_model_detection_function(detection_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Ycfl7rnDT1D","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976563,"user_tz":240,"elapsed":262471,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["#map labels for inference decoding\n","label_map_path = configs['eval_input_config'].label_map_path\n","label_map = label_map_util.load_labelmap(label_map_path)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map,\n","    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n","    use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wN1BzORoIzV4","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596143976564,"user_tz":240,"elapsed":262469,"user":{"displayName":"Tenser fLOW","photoUrl":"","userId":"17367921152229091554"}}},"source":["#run detector on test image\n","#it takes a little longer on the first run and then runs at normal speed. \n","import random\n","\n","#TEST_IMAGE_PATHS = glob.glob('/content/test/test/*.jpg')\n","TEST_IMAGE_PATHS = glob.glob('/content/test/*.jpg')\n","image_path = random.choice(TEST_IMAGE_PATHS)\n","image_np = load_image_into_numpy_array(image_path)\n","\n","# Things to try:\n","# Flip horizontally\n","# image_np = np.fliplr(image_np).copy()\n","\n","# Convert image to grayscale\n","# image_np = np.tile(\n","#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n","\n","input_tensor = tf.convert_to_tensor(\n","    np.expand_dims(image_np, 0), dtype=tf.float32)\n","detections, predictions_dict, shapes = detect_fn(input_tensor)\n","\n","label_id_offset = 1\n","image_np_with_detections = image_np.copy()\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_detections,\n","      detections['detection_boxes'][0].numpy(),\n","      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n","      detections['detection_scores'][0].numpy(),\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=200,\n","      min_score_thresh=.5,\n","      agnostic_mode=False,\n",")\n","\n","plt.figure(figsize=(12,16))\n","plt.imshow(image_np_with_detections)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zQ-N94cKB82o","colab_type":"text"},"source":["## Congrats!\n","\n","Hope you enjoyed this!\n","\n","--Team [Roboflow](https://roboflow.ai)\n"]}]}